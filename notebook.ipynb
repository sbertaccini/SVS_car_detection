{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CARLA Project - Car and distance detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package installation\n",
    "\n",
    "Install the required packages with the following command (run it where the `requirements.txt` file is located):\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.7.16)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seren\\.conda\\envs\\carla\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import carla, time, pygame, math, random, cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from queue import Queue\n",
    "from queue import Empty\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = carla.Client('localhost', 2000)\n",
    "client.set_timeout(20.0)\n",
    "\n",
    "# client.load_world('Town01')\n",
    "world = client.get_world()\n",
    "spectator = world.get_spectator()\n",
    "# world.set_weather(carla.WeatherParameters.ClearNoon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_spectator_to(transform, distance=5.0, x=0, y=0, z=4, yaw=0, pitch=-10, roll=0):\n",
    "    back_location = transform.location - transform.get_forward_vector() * distance\n",
    "    \n",
    "    back_location.x += x\n",
    "    back_location.y += y\n",
    "    back_location.z += z\n",
    "    transform.rotation.yaw += yaw\n",
    "    transform.rotation.pitch = pitch\n",
    "    transform.rotation.roll = roll\n",
    "    \n",
    "    spectator_transform = carla.Transform(back_location, transform.rotation)\n",
    "    \n",
    "    spectator.set_transform(spectator_transform)\n",
    "\n",
    "def spawn_vehicle(vehicle_index=0, spawn_index=0, pattern='vehicle.*'):\n",
    "    blueprint_library = world.get_blueprint_library()\n",
    "    vehicle_bp = blueprint_library.filter(pattern)[vehicle_index]\n",
    "    spawn_point = world.get_map().get_spawn_points()[spawn_index]\n",
    "    vehicle = world.spawn_actor(vehicle_bp, spawn_point)\n",
    "    return vehicle\n",
    "\n",
    "def draw_on_screen(transform, content='O', color=carla.Color(0, 255, 0), life_time=20):\n",
    "    world.debug.draw_string(transform.location, content, color=color, life_time=life_time)\n",
    "\n",
    "def spawn_camera(attach_to=None, transform=carla.Transform(carla.Location(x=1.5, z=1.5), carla.Rotation(pitch=-10)), width=800, height=600, frequency = 0):\n",
    "    camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "    camera_bp.set_attribute('image_size_x', str(width))\n",
    "    camera_bp.set_attribute('image_size_y', str(height))\n",
    "    camera_bp.set_attribute('sensor_tick', str(frequency))\n",
    "    camera = world.spawn_actor(camera_bp, transform, attach_to=attach_to)\n",
    "    return camera\n",
    "\n",
    "def spawn_radar(attach_to=None, transform=carla.Transform(carla.Location(x=1.5, z=1.5), carla.Rotation(pitch=-10)), horizontal_fov = 35, vertical_fov = 20):\n",
    "    radar_bp = world.get_blueprint_library().find('sensor.other.radar')\n",
    "    radar_bp.set_attribute('horizontal_fov', str(horizontal_fov))\n",
    "    radar_bp.set_attribute('vertical_fov', str(vertical_fov))\n",
    "    radar = world.spawn_actor(radar_bp, transform, attach_to=attach_to)\n",
    "    return radar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for actor in world.get_actors().filter('*vehicle*'):\n",
    "  actor.destroy()\n",
    "\n",
    "for actor in world.get_actors().filter('*sensor*'):\n",
    "  actor.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.20  Python-3.7.16 torch-1.10.0+cu113 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "settings = world.get_settings()\n",
    "settings.synchronous_mode = True\n",
    "settings.fixed_delta_seconds = 0.05\n",
    "world.apply_settings(settings)\n",
    "\n",
    "sensor_transform = carla.Transform(carla.Location(x=-0.16, y=-0.9, z=2.4), carla.Rotation(yaw=-100))\n",
    "\n",
    "vehicle = spawn_vehicle(spawn_index=1, pattern=\"vehicle.dodge.charger_2020\")\n",
    "camera = spawn_camera(attach_to=vehicle, transform=sensor_transform, width=320, height=320)\n",
    "radar = spawn_radar(attach_to=vehicle, transform=sensor_transform, horizontal_fov=60, vertical_fov=40)\n",
    "velocity_range = 7.5 # m/s\n",
    "\n",
    "video_output = np.zeros((320, 320, 4), dtype=np.uint8)\n",
    "\n",
    "image_queue = Queue()\n",
    "radar_queue = Queue()\n",
    "\n",
    "def sensor_callback(data, queue):\n",
    "    queue.put(data)\n",
    "\n",
    "camera.listen(lambda data: sensor_callback(data, image_queue))\n",
    "radar.listen(lambda data: sensor_callback(data, radar_queue))\n",
    "\n",
    "vehicle.set_autopilot(True)\n",
    "\n",
    "cv2.namedWindow('Left Side Camera', cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "model = YOLO(\"runs/detect/train2/weights/best.pt\")\n",
    "\n",
    "running = True\n",
    "\n",
    "try:\n",
    "    while running:\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            running = False\n",
    "            break\n",
    "        \n",
    "        world.tick()\n",
    "\n",
    "        try:\n",
    "            # Get the data once it's received.\n",
    "            image_data = image_queue.get(True, 1.0)\n",
    "            radar_data = radar_queue.get(True, 1.0)\n",
    "        except Empty:\n",
    "            print(\"[Warning] Some sensor data has been missed\")\n",
    "            continue\n",
    "\n",
    "        # sync the data\n",
    "        assert image_data.frame == radar_data.frame\n",
    "\n",
    "        # Retrive the image data\n",
    "        video_output = np.reshape(np.copy(image_data.raw_data), (image_data.height, image_data.width, 4))\n",
    "\n",
    "        # ----------- RADAR data -----------\n",
    "\n",
    "        points = np.frombuffer(radar_data.raw_data, dtype=np.dtype('f4'))\n",
    "        points = np.reshape(points, (len(radar_data), 4))\n",
    "\n",
    "        # Filter out points under the radar (altitude < 0) to avoid road surface and other objects\n",
    "        points = points[points[:, 2] <= 0] \n",
    "\n",
    "        # [vel, azimuth, altitude, depth]\n",
    "        velocities = points[:, 0]\n",
    "        azimuth = points[:, 1]\n",
    "        altitude = points[:, 2]\n",
    "        depth = points[:, 3]     \n",
    "\n",
    "        # Convert spherical coordinates to Cartesian (sensor coordinate system)\n",
    "        X = depth * np.cos(altitude) * np.sin(azimuth)\n",
    "        Y = depth * np.sin(altitude)\n",
    "        Z = depth * np.cos(altitude) * np.cos(azimuth)\n",
    "\n",
    "        # Stack into a single array (shape: Nx3)\n",
    "        cartesian_points = np.stack((X, Y, Z), axis=1)\n",
    "\n",
    "        # Build the K projection matrix:\n",
    "        # K = [[Fx,  0, image_w/2],\n",
    "        #      [ 0, Fy, image_h/2],\n",
    "        #      [ 0,  0,         1]]\n",
    "        image_w = 320 #image_size_x\n",
    "        image_h = 320 #image_size_y\n",
    "\n",
    "        #since we are using the standard camera fov\n",
    "        camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "        fov = camera_bp.get_attribute(\"fov\").as_float() \n",
    "        focal = image_w / (2.0 * np.tan(fov * np.pi / 360.0))\n",
    "\n",
    "        # In this case Fx and Fy are the same since the pixel aspect ratio is 1\n",
    "        K = np.identity(3)\n",
    "        K[0, 0] = K[1, 1] = focal\n",
    "        K[0, 2] = image_w / 2.0\n",
    "        K[1, 2] = image_h / 2.0\n",
    "\n",
    "        # cartesian_points.T is a 3xN matrix - can be multiplied directly by K\n",
    "        points_2d = np.dot(K, cartesian_points.T)\n",
    "\n",
    "        # Normalize the points\n",
    "        points_2d = np.array([\n",
    "            points_2d[0, :] / points_2d[2, :],\n",
    "            points_2d[1, :] / points_2d[2, :],\n",
    "            points_2d[2, :]])\n",
    "        \n",
    "        points_2d = points_2d.T\n",
    "\n",
    "        frame = video_output.copy()  # Copy to avoid modifying the original\n",
    "\n",
    "\n",
    "        # ----------- YOLO evaluation -----------\n",
    "\n",
    "        eval_img = video_output[:, :, :3]\n",
    "        results = model(eval_img, imgsz=320)\n",
    "\n",
    "        for result in results:\n",
    "            for i in range(len(result)):\n",
    "                min_distance = 1000\n",
    "                confidence = result.boxes.conf[i]\n",
    "                if confidence < 0.5: # skip if confidence is low\n",
    "                    continue\n",
    "                box = result.boxes.xyxy[i]\n",
    "                for j in range(len(points_2d)):\n",
    "                    if box[0] < points_2d[i][0] < box[2] and box[1] < points_2d[i][1] < box[3]:\n",
    "                        if depth[i] < min_distance:\n",
    "                            min_distance = depth[i]\n",
    "                if min_distance < 1000:\n",
    "                    print(\"Car detected at distance: \", min_distance)\n",
    "            # for box in result.boxes.xyxy:\n",
    "            #     # look for the closest point to the ego vehicle\n",
    "            #     min_distance = 1000\n",
    "            #     for i in range(len(points_2d)):\n",
    "            #         if box[0] < points_2d[i][0] < box[2] and box[1] < points_2d[i][1] < box[3]:\n",
    "            #             if depth[i] < min_distance:\n",
    "            #                 min_distance = depth[i]\n",
    "            #     if min_distance < 1000:\n",
    "            #         print(\"Car detected at distance: \", min_distance)\n",
    "\n",
    "\n",
    "        # ----------- DISPLAY ON SCREEN FOR DEBUG -----------\n",
    "\n",
    "        # Loop through all projected 2D points\n",
    "        for point in points_2d:\n",
    "            x, y = int(point[0]), int(point[1])  # Convert to integer pixel coordinates\n",
    "\n",
    "            # Draw the point only if it is inside the image frame\n",
    "            if 0 <= x < frame.shape[1] and 0 <= y < frame.shape[0]:\n",
    "                cv2.circle(frame, (x, y), radius=2, color=(0, 0, 255), thickness=-1)  # Red dot\n",
    "\n",
    "        \n",
    "        for result in results:\n",
    "            # print(result.boxes.xyxy)\n",
    "            for box in result.boxes.xyxy:\n",
    "                cv2.rectangle(frame, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (0, 255, 0), 1)\n",
    "\n",
    "        # Show the image with radar points overlaid\n",
    "        cv2.imshow('Left Side Camera', frame)\n",
    "finally:\n",
    "    cv2.destroyAllWindows()\n",
    "    camera.destroy()\n",
    "    vehicle.destroy()\n",
    "    radar.destroy()\n",
    "    settings = world.get_settings()\n",
    "    settings.synchronous_mode = False\n",
    "    settings.no_rendering_mode = False\n",
    "    settings.fixed_delta_seconds = None\n",
    "    world.apply_settings(settings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

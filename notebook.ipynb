{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CARLA Project - Car and distance detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package installation\n",
    "\n",
    "Install the required packages with the following command (run it where the `requirements.txt` file is located):\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla, cv2\n",
    "import numpy as np\n",
    "from queue import Queue\n",
    "from queue import Empty\n",
    "from ultralytics import YOLO\n",
    "import paho.mqtt.client as mqtt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = carla.Client('localhost', 2000)\n",
    "client.set_timeout(10.0)\n",
    "\n",
    "world = client.get_world()\n",
    "spectator = world.get_spectator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spawn_vehicle(vehicle_index=0, spawn_index=0, pattern='vehicle.*'):\n",
    "    blueprint_library = world.get_blueprint_library()\n",
    "    vehicle_bp = blueprint_library.filter(pattern)[vehicle_index]\n",
    "    spawn_point = world.get_map().get_spawn_points()[spawn_index]\n",
    "    vehicle = world.spawn_actor(vehicle_bp, spawn_point)\n",
    "    return vehicle\n",
    "\n",
    "def spawn_camera(attach_to=None, transform=carla.Transform(carla.Location(x=1.5, z=1.5), carla.Rotation(pitch=-10)), width=800, height=600, frequency = 0):\n",
    "    camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "    camera_bp.set_attribute('image_size_x', str(width))\n",
    "    camera_bp.set_attribute('image_size_y', str(height))\n",
    "    camera_bp.set_attribute('sensor_tick', str(frequency))\n",
    "    camera = world.spawn_actor(camera_bp, transform, attach_to=attach_to)\n",
    "    return camera\n",
    "\n",
    "def spawn_radar(attach_to=None, transform=carla.Transform(carla.Location(x=1.5, z=1.5), carla.Rotation(pitch=-10)), horizontal_fov = 35, vertical_fov = 20):\n",
    "    radar_bp = world.get_blueprint_library().find('sensor.other.radar')\n",
    "    radar_bp.set_attribute('horizontal_fov', str(horizontal_fov))\n",
    "    radar_bp.set_attribute('vertical_fov', str(vertical_fov))\n",
    "    radar = world.spawn_actor(radar_bp, transform, attach_to=attach_to)\n",
    "    return radar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the world from previous actors\n",
    "for actor in world.get_actors().filter('*vehicle*'):\n",
    "  actor.destroy()\n",
    "\n",
    "for actor in world.get_actors().filter('*sensor*'):\n",
    "  actor.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = world.get_settings()\n",
    "settings.synchronous_mode = True\n",
    "settings.fixed_delta_seconds = 0.05\n",
    "world.apply_settings(settings)\n",
    "\n",
    "# -------------- Connection to MQTT broker --------------\n",
    "broker_address = \"localhost\"  # Change to your broker address\n",
    "port = 1883  # Default MQTT port\n",
    "topic = \"car_distance\"\n",
    "\n",
    "client = mqtt.Client()\n",
    "client.connect(broker_address, port)\n",
    "\n",
    "# Load the YOLO model\n",
    "model = YOLO(\"runs/detect/train2/weights/best.pt\")\n",
    "\n",
    "# Sensors configuration\n",
    "img_size = 320\n",
    "transforms = [\n",
    "    carla.Transform(carla.Location(x=-0.16, y=-0.9, z=2.4), carla.Rotation(yaw=-100)),  # [0] Left side camera  \n",
    "    carla.Transform(carla.Location(x=-0.16, y=0.9, z=2.4), carla.Rotation(yaw=100)),    # [1] Right side camera\n",
    "    carla.Transform(carla.Location(x=1.5, z=2.4)),                                      # [2] Front camera\n",
    "    carla.Transform(carla.Location(x=-1.5, z=2.4), carla.Rotation(yaw=180))             # [3] Rear camera\n",
    "]\n",
    "\n",
    "vehicle = spawn_vehicle(spawn_index=10, pattern=\"vehicle.dodge.charger_2020\")\n",
    "\n",
    "video_outputs = [np.zeros((img_size, img_size, 4), dtype=np.uint8) for _ in range(4)]\n",
    "\n",
    "# Thread-safe queues to store the sensor data\n",
    "image_queues = [Queue() for _ in range(4)]\n",
    "radar_queues = [Queue() for _ in range(4)]\n",
    "\n",
    "def sensor_callback(data, queue):\n",
    "    queue.put(data)\n",
    "\n",
    "cameras = []\n",
    "radars = []\n",
    "\n",
    "for i in range(4):\n",
    "    camera = spawn_camera(attach_to=vehicle, transform=transforms[i], width=img_size, height=img_size)\n",
    "    radar = spawn_radar(attach_to=vehicle, transform=transforms[i], horizontal_fov=60, vertical_fov=40)\n",
    "    camera.listen(lambda data, idx=i: sensor_callback(data, image_queues[idx]))\n",
    "    radar.listen(lambda data, idx=i: sensor_callback(data, radar_queues[idx]))\n",
    "    cameras.append(camera)\n",
    "    radars.append(radar)\n",
    "\n",
    "vehicle.set_autopilot(True)\n",
    "\n",
    "#Windows configuration\n",
    "window_names = ['Left Side Camera', 'Right Side Camera', 'Front Camera', 'Rear Camera']\n",
    "\n",
    "for i in range(4):\n",
    "    cv2.namedWindow(window_names[i], cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "# Build the K projection matrix: - used later to project the radar points into the image plane\n",
    "# K = [[Fx,  0, image_w/2],\n",
    "#      [ 0, Fy, image_h/2],\n",
    "#      [ 0,  0,         1]]\n",
    "# image_w = image_h = img_size \n",
    "\n",
    "#since we are using the standard camera fov\n",
    "camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "fov = camera_bp.get_attribute(\"fov\").as_float() \n",
    "focal = img_size / (2.0 * np.tan(fov * np.pi / 360.0))\n",
    "\n",
    "# In this case Fx and Fy are the same since the pixel aspect ratio is 1\n",
    "K = np.identity(3)\n",
    "K[0, 0] = K[1, 1] = focal\n",
    "K[0, 2] = img_size / 2.0\n",
    "K[1, 2] = img_size / 2.0\n",
    "\n",
    "running = True\n",
    "\n",
    "try:\n",
    "    while running:\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            running = False\n",
    "            break\n",
    "        \n",
    "        world.tick()\n",
    "\n",
    "        for k in range(4): # k = for each camera\n",
    "            try:\n",
    "                # Get the data once it's received.\n",
    "                image_data = image_queues[k].get(True, 1.0)\n",
    "                radar_data = radar_queues[k].get(True, 1.0)\n",
    "            except Empty:\n",
    "                print(\"[Warning] Some sensor data has been missed\")\n",
    "                continue\n",
    "\n",
    "            # sync the data\n",
    "            assert image_data.frame == radar_data.frame\n",
    "\n",
    "            # Retrive the image data\n",
    "            video_outputs[k] = np.reshape(np.copy(image_data.raw_data), (image_data.height, image_data.width, 4))\n",
    "\n",
    "            # ----------- RADAR data -----------\n",
    "\n",
    "            current_rot = radar_data.transform.rotation\n",
    "\n",
    "            points = np.frombuffer(radar_data.raw_data, dtype=np.dtype('f4'))\n",
    "            points = np.reshape(points, (len(radar_data), 4))\n",
    "\n",
    "            # [vel, azimuth, altitude, depth]\n",
    "            azimuth = points[:, 1]\n",
    "            altitude = points[:, 2]\n",
    "            depth = points[:, 3]\n",
    "\n",
    "            # Convert spherical coordinates to Cartesian (sensor coordinate system)\n",
    "            X = depth * np.cos(altitude) * np.cos(azimuth)\n",
    "            Y = depth * np.cos(altitude) * np.sin(azimuth)\n",
    "            Z = depth * np.sin(altitude)\n",
    "\n",
    "            # Stack into a single array (shape: Nx3)\n",
    "            cartesian_points = np.stack((X, Y, Z), axis=1)\n",
    "\n",
    "            cartesian_points = cartesian_points.T # Transpose to 3xN\n",
    "\n",
    "            # change from UE4's coordinate system to an \"standard\" camera coordinate system (the same used by OpenCV):\n",
    "            point_in_std_camera_coords = np.array([\n",
    "                    cartesian_points[1],\n",
    "                    cartesian_points[2] * -1,\n",
    "                    cartesian_points[0]])\n",
    "\n",
    "            # Project the 3D points into the 2D image with the K matrix\n",
    "            points_2d = np.dot(K, point_in_std_camera_coords)\n",
    "\n",
    "            # Normalize the points\n",
    "            points_2d = np.array([\n",
    "                points_2d[0, :] / points_2d[2, :],\n",
    "                points_2d[1, :] / points_2d[2, :],\n",
    "                points_2d[2, :]])\n",
    "            \n",
    "            points_2d = points_2d.T\n",
    "\n",
    "            frame = video_outputs[k].copy()  # Copy to avoid modifying the original\n",
    "\n",
    "            # ----------- YOLO evaluation -----------\n",
    "\n",
    "            eval_img = frame[:, :, :3]\n",
    "            results = model(eval_img, imgsz=img_size)\n",
    "\n",
    "            for result in results:\n",
    "                for i in range(len(result)): # i = for each detected object\n",
    "                    min_distance = -1\n",
    "                    confidence = result.boxes.conf[i]\n",
    "                    if confidence < 0.5: # skip if confidence is low\n",
    "                        continue\n",
    "                    box = result.boxes.xyxy[i]\n",
    "                    cv2.rectangle(frame, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (0, 255, 0), 1)\n",
    "\n",
    "                    for j in range(len(points_2d)): # j = for each radar point\n",
    "                        if min_distance == -1:\n",
    "                            min_distance = depth[j]\n",
    "\n",
    "                        x, y = int(points_2d[j][0]), int(points_2d[j][1])\n",
    "                        if box[0] < x < box[2] and box[1] < y < box[3]:\n",
    "                            cv2.circle(frame, (x, y), radius=2, color=(0, 0, 255), thickness=-1)\n",
    "                            if depth[j] < min_distance:\n",
    "                                min_distance = depth[j]\n",
    "                    if min_distance != -1:\n",
    "                        message = f\"{window_names[k]} - Car [{i}] detected at distance: {min_distance}\"\n",
    "                        client.publish(topic, message)\n",
    "                        # print(window_names[k],\" - Car [\", i ,\"] detected at distance: \", min_distance)\n",
    "                    else:\n",
    "                        print(\"[Warning] \",window_names[k],\" - no radar data on car\")\n",
    "            \n",
    "            cv2.imshow(window_names[k], frame)\n",
    "finally:\n",
    "    client.disconnect()\n",
    "    cv2.destroyAllWindows()\n",
    "    vehicle.destroy()\n",
    "    for camera in cameras:\n",
    "        camera.destroy()\n",
    "    for radar in radars:\n",
    "        radar.destroy()\n",
    "    settings = world.get_settings()\n",
    "    settings.synchronous_mode = False\n",
    "    settings.no_rendering_mode = False\n",
    "    settings.fixed_delta_seconds = None\n",
    "    world.apply_settings(settings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

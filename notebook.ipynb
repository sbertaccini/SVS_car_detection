{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CARLA Project - Car and distance detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package installation\n",
    "\n",
    "Install the required packages with the following command (run it where the `requirements.txt` file is located):\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.7.16)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seren\\.conda\\envs\\carla\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import carla, time, pygame, math, random, cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from queue import Queue\n",
    "from queue import Empty\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = carla.Client('localhost', 2000)\n",
    "client.set_timeout(20.0)\n",
    "\n",
    "# client.load_world('Town01')\n",
    "world = client.get_world()\n",
    "spectator = world.get_spectator()\n",
    "# world.set_weather(carla.WeatherParameters.ClearNoon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_spectator_to(transform, distance=5.0, x=0, y=0, z=4, yaw=0, pitch=-10, roll=0):\n",
    "    back_location = transform.location - transform.get_forward_vector() * distance\n",
    "    \n",
    "    back_location.x += x\n",
    "    back_location.y += y\n",
    "    back_location.z += z\n",
    "    transform.rotation.yaw += yaw\n",
    "    transform.rotation.pitch = pitch\n",
    "    transform.rotation.roll = roll\n",
    "    \n",
    "    spectator_transform = carla.Transform(back_location, transform.rotation)\n",
    "    \n",
    "    spectator.set_transform(spectator_transform)\n",
    "\n",
    "def spawn_vehicle(vehicle_index=0, spawn_index=0, pattern='vehicle.*'):\n",
    "    blueprint_library = world.get_blueprint_library()\n",
    "    vehicle_bp = blueprint_library.filter(pattern)[vehicle_index]\n",
    "    spawn_point = world.get_map().get_spawn_points()[spawn_index]\n",
    "    vehicle = world.spawn_actor(vehicle_bp, spawn_point)\n",
    "    return vehicle\n",
    "\n",
    "def draw_on_screen(transform, content='O', color=carla.Color(0, 255, 0), life_time=20):\n",
    "    world.debug.draw_string(transform.location, content, color=color, life_time=life_time)\n",
    "\n",
    "def spawn_camera(attach_to=None, transform=carla.Transform(carla.Location(x=1.5, z=1.5), carla.Rotation(pitch=-10)), width=800, height=600, frequency = 0):\n",
    "    camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "    camera_bp.set_attribute('image_size_x', str(width))\n",
    "    camera_bp.set_attribute('image_size_y', str(height))\n",
    "    camera_bp.set_attribute('sensor_tick', str(frequency))\n",
    "    camera = world.spawn_actor(camera_bp, transform, attach_to=attach_to)\n",
    "    return camera\n",
    "\n",
    "def spawn_radar(attach_to=None, transform=carla.Transform(carla.Location(x=1.5, z=1.5), carla.Rotation(pitch=-10)), horizontal_fov = 35, vertical_fov = 20):\n",
    "    radar_bp = world.get_blueprint_library().find('sensor.other.radar')\n",
    "    radar_bp.set_attribute('horizontal_fov', str(horizontal_fov))\n",
    "    radar_bp.set_attribute('vertical_fov', str(vertical_fov))\n",
    "    radar = world.spawn_actor(radar_bp, transform, attach_to=attach_to)\n",
    "    return radar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for actor in world.get_actors().filter('*vehicle*'):\n",
    "  actor.destroy()\n",
    "\n",
    "for actor in world.get_actors().filter('*sensor*'):\n",
    "  actor.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.20  Python-3.7.16 torch-1.10.0+cu113 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "settings = world.get_settings()\n",
    "settings.synchronous_mode = True\n",
    "settings.fixed_delta_seconds = 0.05\n",
    "world.apply_settings(settings)\n",
    "\n",
    "sensor_transform = carla.Transform(carla.Location(x=-0.16, y=-0.9, z=2.4), carla.Rotation(yaw=-100))\n",
    "\n",
    "vehicle = spawn_vehicle(spawn_index=20, pattern=\"vehicle.dodge.charger_2020\")\n",
    "camera = spawn_camera(attach_to=vehicle, transform=sensor_transform, width=320, height=320)\n",
    "radar = spawn_radar(attach_to=vehicle, transform=sensor_transform, horizontal_fov=60, vertical_fov=40)\n",
    "velocity_range = 7.5 # m/s\n",
    "\n",
    "video_output = np.zeros((320, 320, 4), dtype=np.uint8)\n",
    "\n",
    "image_queue = Queue()\n",
    "radar_queue = Queue()\n",
    "\n",
    "def sensor_callback(data, queue):\n",
    "    queue.put(data)\n",
    "\n",
    "camera.listen(lambda data: sensor_callback(data, image_queue))\n",
    "radar.listen(lambda data: sensor_callback(data, radar_queue))\n",
    "\n",
    "vehicle.set_autopilot(True)\n",
    "\n",
    "cv2.namedWindow('Left Side Camera', cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "model = YOLO(\"runs/detect/train2/weights/best.pt\")\n",
    "\n",
    "running = True\n",
    "\n",
    "try:\n",
    "    while running:\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            running = False\n",
    "            break\n",
    "        \n",
    "        world.tick()\n",
    "\n",
    "        try:\n",
    "            # Get the data once it's received.\n",
    "            image_data = image_queue.get(True, 1.0)\n",
    "            radar_data = radar_queue.get(True, 1.0)\n",
    "        except Empty:\n",
    "            print(\"[Warning] Some sensor data has been missed\")\n",
    "            continue\n",
    "\n",
    "        # sync the data\n",
    "        assert image_data.frame == radar_data.frame\n",
    "\n",
    "        # Retrive the image data\n",
    "        video_output = np.reshape(np.copy(image_data.raw_data), (image_data.height, image_data.width, 4))\n",
    "\n",
    "        # ----------- RADAR data -----------\n",
    "\n",
    "        points = np.frombuffer(radar_data.raw_data, dtype=np.dtype('f4'))\n",
    "        points = np.reshape(points, (len(radar_data), 4))\n",
    "\n",
    "        # [vel, azimuth, altitude, depth]\n",
    "        velocities = points[:, 0]\n",
    "        azimuth = points[:, 1]\n",
    "        altitude = points[:, 2]\n",
    "        depth = points[:, 3]     \n",
    "\n",
    "        # Convert spherical coordinates to Cartesian (sensor coordinate system)\n",
    "        X = depth * np.cos(altitude) * np.sin(azimuth)\n",
    "        Y = depth * np.sin(altitude)\n",
    "        Z = depth * np.cos(altitude) * np.cos(azimuth)\n",
    "\n",
    "        # Stack into a single array (shape: Nx3)\n",
    "        cartesian_points = np.stack((X, Y, Z), axis=1)\n",
    "\n",
    "        # Build the K projection matrix:\n",
    "        # K = [[Fx,  0, image_w/2],\n",
    "        #      [ 0, Fy, image_h/2],\n",
    "        #      [ 0,  0,         1]]\n",
    "        image_w = 320 #image_size_x\n",
    "        image_h = 320 #image_size_y\n",
    "\n",
    "        #since we are using the standard camera fov\n",
    "        camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "        fov = camera_bp.get_attribute(\"fov\").as_float() \n",
    "        focal = image_w / (2.0 * np.tan(fov * np.pi / 360.0))\n",
    "\n",
    "        # In this case Fx and Fy are the same since the pixel aspect ratio is 1\n",
    "        K = np.identity(3)\n",
    "        K[0, 0] = K[1, 1] = focal\n",
    "        K[0, 2] = image_w / 2.0\n",
    "        K[1, 2] = image_h / 2.0\n",
    "\n",
    "        # cartesian_points.T is a 3xN matrix - can be multiplied directly by K\n",
    "        points_2d = np.dot(K, cartesian_points.T)\n",
    "\n",
    "        # Normalize the points\n",
    "        points_2d = np.array([\n",
    "            points_2d[0, :] / points_2d[2, :],\n",
    "            points_2d[1, :] / points_2d[2, :],\n",
    "            points_2d[2, :]])\n",
    "        \n",
    "        points_2d = points_2d.T\n",
    "\n",
    "        frame = video_output.copy()  # Copy to avoid modifying the original\n",
    "\n",
    "        # Loop through all projected 2D points\n",
    "        for point in points_2d:\n",
    "            x, y = int(point[0]), int(point[1])  # Convert to integer pixel coordinates\n",
    "\n",
    "            # Draw the point only if it is inside the image frame\n",
    "            if 0 <= x < frame.shape[1] and 0 <= y < frame.shape[0]:\n",
    "                cv2.circle(frame, (x, y), radius=2, color=(0, 0, 255), thickness=-1)  # Red dot\n",
    "\n",
    "        # ----------- YOLO evaluation -----------\n",
    "\n",
    "        eval_img = video_output[:, :, :3]\n",
    "        results = model(eval_img, imgsz=320)\n",
    "        for result in results:\n",
    "            # print(result.boxes.xyxy)\n",
    "            for box in result.boxes.xyxy:\n",
    "                cv2.rectangle(frame, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (0, 255, 0), 1)\n",
    "\n",
    "        # Show the image with radar points overlaid\n",
    "        cv2.imshow('Left Side Camera', frame)\n",
    "finally:\n",
    "    cv2.destroyAllWindows()\n",
    "    camera.destroy()\n",
    "    vehicle.destroy()\n",
    "    radar.destroy()\n",
    "    settings = world.get_settings()\n",
    "    settings.synchronous_mode = False\n",
    "    settings.no_rendering_mode = False\n",
    "    settings.fixed_delta_seconds = None\n",
    "    world.apply_settings(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # current_rot = radar_data.transform.rotation\n",
    "    # for detect in radar_data:\n",
    "    #     azi = math.degrees(detect.azimuth)\n",
    "    #     alt = math.degrees(detect.altitude)\n",
    "    #     # The 0.25 adjusts a bit the distance so the dots can be properly seen\n",
    "    #     fw_vec = carla.Vector3D(x=detect.depth)\n",
    "    #     # fw_vec = carla.Vector3D(x=detect.depth - 0.25)\n",
    "    #     carla.Transform(\n",
    "    #         carla.Location(),\n",
    "    #         carla.Rotation(\n",
    "    #             pitch=current_rot.pitch + alt,\n",
    "    #             yaw=current_rot.yaw + azi,\n",
    "    #             roll=current_rot.roll)).transform(fw_vec)\n",
    "\n",
    "    #     def clamp(min_v, max_v, value):\n",
    "    #         return max(min_v, min(value, max_v))\n",
    "\n",
    "    #     norm_velocity = detect.velocity / velocity_range # range [-1, 1]\n",
    "    #     r = int(clamp(0.0, 1.0, 1.0 - norm_velocity) * 255.0)\n",
    "    #     g = int(clamp(0.0, 1.0, 1.0 - abs(norm_velocity)) * 255.0)\n",
    "    #     b = int(abs(clamp(- 1.0, 0.0, - 1.0 - norm_velocity)) * 255.0)\n",
    "    #     world.debug.draw_point(\n",
    "    #         radar_data.transform.location + fw_vec,\n",
    "    #         size=0.075,\n",
    "    #         life_time=0.06,\n",
    "    #         persistent_lines=False,\n",
    "    #         color=carla.Color(r, g, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings = world.get_settings()\n",
    "# settings.synchronous_mode = True\n",
    "# settings.fixed_delta_seconds = 0.05\n",
    "# world.apply_settings(settings)\n",
    "\n",
    "# vehicle = spawn_vehicle(spawn_index=0, pattern=\"vehicle.dodge.charger_2020\")\n",
    "# camera = spawn_camera(attach_to=vehicle, transform=carla.Transform(carla.Location(x=-0.16, y=-0.9, z=2.4), carla.Rotation(yaw=-100)), frequency=0.2, width=300, height=300)\n",
    "# video_output = np.zeros((300, 300, 4), dtype=np.uint8)\n",
    "# car_label = \"\"\n",
    "\n",
    "# def camera_callback(image):\n",
    "#     global video_output\n",
    "#     global car_label\n",
    "    \n",
    "#     image_data = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "    \n",
    "#     # Convert the array to a PIL Image (RGB)\n",
    "#     image_rgb = Image.fromarray(image_data[:, :, :3])  # Ignore the alpha channel\n",
    "    \n",
    "#     # Preprocess the image for the model\n",
    "#     image_tensor = transform(image_rgb).unsqueeze(0)  # Add batch dimension\n",
    "    \n",
    "#     # Perform prediction\n",
    "#     with torch.no_grad():\n",
    "#         output = model(image_tensor)  # Get model output\n",
    "#         _, predicted = torch.max(output, 1)  # Get the predicted class\n",
    "    \n",
    "#     # Set the car label based on the prediction\n",
    "#     if predicted.item() == 0:\n",
    "#         car_label = \"Car detected\"\n",
    "#     else:\n",
    "#         car_label = \"No car detected\"\n",
    "\n",
    "#     # Update video output (for visualization)\n",
    "#     video_output = image_data\n",
    "#     cv2.putText(video_output, car_label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "# camera.listen(camera_callback)\n",
    "\n",
    "# vehicle.set_autopilot(True, 8000)\n",
    "\n",
    "# cv2.namedWindow('Left Side Camera', cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "# running = True\n",
    "\n",
    "# try:\n",
    "#   while running:\n",
    "#     if cv2.waitKey(1) == ord('q'):\n",
    "#         running = False\n",
    "#         break\n",
    "#     cv2.imshow('Left Side Camera', video_output)\n",
    "#     world.tick()\n",
    "# finally:\n",
    "#   cv2.destroyAllWindows()\n",
    "#   camera.destroy()\n",
    "#   vehicle.destroy()\n",
    "#   settings = world.get_settings()\n",
    "#   settings.synchronous_mode = False\n",
    "#   settings.no_rendering_mode = False\n",
    "#   settings.fixed_delta_seconds = None\n",
    "#   world.apply_settings(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Define the model architecture\n",
    "# model = models.mobilenet_v2()\n",
    "\n",
    "# # Modify the classifier layer to match the saved state dictionary\n",
    "# model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, 2)\n",
    "\n",
    "# # Load the state dictionary\n",
    "# state_dict = torch.load(\"mobilenet_v2_finetuned.pth\")\n",
    "\n",
    "# # Load the state dictionary into the model\n",
    "# model.load_state_dict(state_dict)\n",
    "\n",
    "# # Set the model to evaluation mode\n",
    "# model.eval()\n",
    "\n",
    "# # Define the image transform (adjust according to your model's requirements)\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Resize((224, 224)),  # Adjust to match your model's expected input size\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Adjust if needed\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings = world.get_settings()\n",
    "# settings.synchronous_mode = True\n",
    "# settings.fixed_delta_seconds = 0.05\n",
    "# world.apply_settings(settings)\n",
    "\n",
    "# vehicle = spawn_vehicle(spawn_index=40, pattern=\"vehicle.dodge.charger_2020\")\n",
    "  \n",
    "# transforms = [\n",
    "#     carla.Transform(carla.Location(x=-0.16, y=-0.9, z=2.4), carla.Rotation(yaw=-100)),  # Left side camera\n",
    "#     carla.Transform(carla.Location(x=-0.16, y=0.9, z=2.4), carla.Rotation(yaw=100)),  # Right side camera\n",
    "#     carla.Transform(carla.Location(x=-1.5, z=2.4), carla.Rotation(yaw=180))  # Rear camera\n",
    "# ]\n",
    "# cameras = []\n",
    "\n",
    "# video_outputs = [np.zeros((300, 300, 4), dtype=np.uint8) for _ in range(3)]\n",
    "# def create_camera_callback(index):\n",
    "#   def camera_callback(image):\n",
    "#       global video_outputs\n",
    "#       video_outputs[index] = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "#   return camera_callback\n",
    "\n",
    "# for i in range(3):\n",
    "#   camera = spawn_camera(attach_to=vehicle, transform=transforms[i], frequency=0.5, width=300, height=300)\n",
    "#   camera.listen(create_camera_callback(i))\n",
    "#   cameras.append(camera)\n",
    "\n",
    "# vehicle.set_autopilot(True, 8000)\n",
    "\n",
    "# cv2.namedWindow('Left Side Camera', cv2.WINDOW_AUTOSIZE)\n",
    "# cv2.namedWindow('Right Side Camera', cv2.WINDOW_AUTOSIZE)\n",
    "# cv2.namedWindow('Rear Camera', cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "# running = True\n",
    "\n",
    "# try:\n",
    "#   while running:\n",
    "#     if cv2.waitKey(1) == ord('q'):\n",
    "#         running = False\n",
    "#         break\n",
    "#     cv2.imshow('Left Side Camera', video_outputs[1])\n",
    "#     cv2.imshow('Right Side Camera', video_outputs[2])\n",
    "#     cv2.imshow('Rear Camera', video_outputs[3])\n",
    "# finally:\n",
    "#   cv2.destroyAllWindows()\n",
    "#   for camera in cameras:\n",
    "#       camera.destroy()\n",
    "#   vehicle.destroy()\n",
    "#   settings = world.get_settings()\n",
    "#   settings.synchronous_mode = False\n",
    "#   settings.no_rendering_mode = False\n",
    "#   settings.fixed_delta_seconds = None\n",
    "#   world.apply_settings(settings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
